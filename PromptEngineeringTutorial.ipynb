{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt engineering and ChatGPT tutorial\n",
    "- プロンプトエンジニアリングについての概観を把握する\n",
    "- 紹介されているtipsを実際に試してみて、自分が作ろうとしているアプリにはどのように使用できそうか、イメージを膨らませる\n",
    "\n",
    "\n",
    "## Prompt engineeringについて\n",
    "- [OpenAI Cookbook](https://github.com/openai/openai-cookbook)\n",
    "- [OpenAI Prompt engineering](https://help.openai.com/en/collections/3675942-prompt-engineering)\n",
    "    - https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api\n",
    "- [Lil' Log, Prompt Engineering(様々なまとめブログを書いている人のプロンプトエンジニアリングについての記事)](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)\n",
    "- [Prompt Engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)\n",
    "    - https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/lecture/Prompt-Engineering-Lecture-Elvis.pdf\n",
    "    - https://www.promptingguide.ai/notebooks\n",
    "- [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPTに論文の要点を箇条書きにしてもらおう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: pdf_files/language_understanding_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "pdf_url = 'https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf'\n",
    "r = requests.get(pdf_url)\n",
    "if r.status_code != 200:\n",
    "    raise ValueError(\n",
    "        \"Check the url of your file; returned status code %s\"\n",
    "        % r.status_code\n",
    "    )\n",
    "\n",
    "# ファイル名を取得します\n",
    "parsed_url = urlparse(pdf_url)\n",
    "file_name = os.path.basename(parsed_url.path)\n",
    "\n",
    "# pdf_filesディレクトリを作成し、ファイルを保存します\n",
    "pdf_files_directory = Path(\"pdf_files\")\n",
    "pdf_files_directory.mkdir(exist_ok=True)\n",
    "file_path = pdf_files_directory / file_name\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "print(f\"File saved at: {file_path}\")\n",
    "from pdfminer.high_level import extract_text\n",
    "text = extract_text(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improving Language Understanding\n",
      "by Generative Pre-Training\n",
      "\n",
      "Alec Radford\n",
      "OpenAI\n",
      "alec@openai.com\n",
      "\n",
      "Karthik Narasimhan\n",
      "OpenAI\n",
      "karthikn@openai.com\n",
      "\n",
      "Tim Salimans\n",
      "OpenAI\n",
      "tim@openai.com\n",
      "\n",
      "Ilya Sutskever\n",
      "OpenAI\n",
      "ilyasu@openai.com\n",
      "\n",
      "Abstract\n",
      "\n",
      "Natural language understanding comprises a wide range of diverse tas\n"
     ]
    }
   ],
   "source": [
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract\n",
      "chunk_idx: 5\n",
      "Introduction\n",
      "chunk_idx: 8\n",
      "2 Related Work\n",
      "chunk_idx: 16\n",
      "3 Framework\n",
      "chunk_idx: 24\n",
      "4 Experiments\n",
      "chunk_idx: 57\n",
      "Task\n",
      "chunk_idx: 62\n",
      "Datasets\n",
      "chunk_idx: 63\n",
      "Method\n",
      "chunk_idx: 76\n",
      "MNLI-m MNLI-mm SNLI\n",
      "chunk_idx: 77\n",
      "SciTail QNLI RTE\n",
      "chunk_idx: 78\n",
      "Method\n",
      "chunk_idx: 106\n",
      "Story Cloze RACE-m RACE-h RACE\n",
      "chunk_idx: 107\n",
      "Method\n",
      "chunk_idx: 128\n",
      "Classiﬁcation\n",
      "chunk_idx: 129\n",
      "Semantic Similarity\n",
      "chunk_idx: 130\n",
      "GLUE\n",
      "chunk_idx: 131\n",
      "5 Analysis\n",
      "chunk_idx: 171\n",
      "Method\n",
      "chunk_idx: 177\n",
      "Avg. Score\n",
      "chunk_idx: 178\n",
      "6 Conclusion\n",
      "chunk_idx: 209\n",
      "References\n",
      "chunk_idx: 211\n"
     ]
    }
   ],
   "source": [
    "def is_digit_or_uppercase_word(element):\n",
    "    if element.isdigit() or element[0].isupper():\n",
    "        return True\n",
    "    return False\n",
    "chunk_idx = []\n",
    "chunk_key_names = []\n",
    "for idx, chunk in enumerate(text.split('\\n\\n')):\n",
    "    chunk_elements = chunk.split()\n",
    "    chunk_judgement = [is_digit_or_uppercase_word(element) for element in chunk_elements]\n",
    "    if all(chunk_judgement):\n",
    "        if len(chunk) > 3:\n",
    "            print(chunk)\n",
    "            print('chunk_idx:', idx)\n",
    "            chunk_idx.append(idx)\n",
    "            chunk_key_names.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_dict = dict()\n",
    "\n",
    "for idx, chunk_key_name in enumerate(chunk_key_names):\n",
    "    if idx == len(chunk_key_names) - 1:\n",
    "        chunk_dict[chunk_key_name] = (chunk_idx[idx], len(text.split('\\n\\n')))\n",
    "    else:\n",
    "        chunk_dict[chunk_key_name] = (chunk_idx[idx], chunk_idx[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abstract': (5, 8),\n",
       " 'Introduction': (8, 16),\n",
       " '2 Related Work': (16, 24),\n",
       " '3 Framework': (24, 57),\n",
       " '4 Experiments': (57, 62),\n",
       " 'Task': (62, 63),\n",
       " 'Datasets': (63, 76),\n",
       " 'Method': (177, 178),\n",
       " 'MNLI-m MNLI-mm SNLI': (77, 78),\n",
       " 'SciTail QNLI RTE': (78, 106),\n",
       " 'Story Cloze RACE-m RACE-h RACE': (107, 128),\n",
       " 'Classiﬁcation': (129, 130),\n",
       " 'Semantic Similarity': (130, 131),\n",
       " 'GLUE': (131, 171),\n",
       " '5 Analysis': (171, 177),\n",
       " 'Avg. Score': (178, 209),\n",
       " '6 Conclusion': (209, 211),\n",
       " 'References': (211, 332)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = dict()\n",
    "for chunk_key_name in chunk_dict.keys():\n",
    "    # print(chunk_key_name)\n",
    "    sentences = text.split('\\n\\n')[chunk_dict[chunk_key_name][0]+1:chunk_dict[chunk_key_name][1]]\n",
    "    sentences = ' '.join(sentences)\n",
    "    sentences = sentences.replace('\\n', ' ')\n",
    "    # print(sentences)\n",
    "    sections[chunk_key_name] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-71B86N0lXY2EBRonp9l56cZTCzP3L at 0x10c505540> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Orange who?\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1680515466,\n",
       "  \"id\": \"chatcmpl-71B86N0lXY2EBRonp9l56cZTCzP3L\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 3,\n",
       "    \"prompt_tokens\": 39,\n",
       "    \"total_tokens\": 42\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install --upgrade openai\n",
    "# https://platform.openai.com/account/api-keys\n",
    "\n",
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb\n",
    "import openai\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections['Abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-71B87kIMQJVFDQ7CMaKR72HwTpZKu at 0x107e964a0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"- Learning effectively from raw text is important in natural language processing (NLP)\\n- Deep learning methods require substantial amounts of manually labeled data, which limits their applicability in many domains\\n- Models that can leverage linguistic information from unlabeled data provide a valuable alternative to gathering more annotation\\n- Learning good representations in an unsupervised fashion can provide a significant performance boost\\n- Pre-trained word embeddings have been extensively used to improve performance on a range of NLP tasks\\n- Leveraging more than word-level information from unlabeled text is challenging due to uncertainties in optimization objectives and transfer techniques\\n- The paper proposes a semi-supervised approach for language understanding tasks using a combination of unsupervised pre-training and supervised fine-tuning\\n- The approach uses a two-stage training procedure and the Transformer model architecture\\n- The approach outperforms discriminatively trained models that employ architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied\\n- The pre-trained model acquires useful linguistic knowledge for downstream tasks.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1680515467,\n",
       "  \"id\": \"chatcmpl-71B87kIMQJVFDQ7CMaKR72HwTpZKu\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 213,\n",
       "    \"prompt_tokens\": 863,\n",
       "    \"total_tokens\": 1076\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_prompt = f\"\"\"\n",
    "Summarize the text below as a bullet point list of the most important points.\n",
    "\n",
    "Text: ###\n",
    "{sections['Introduction']}\n",
    "###\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": gpt_prompt},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Learning effectively from raw text is important in natural language processing (NLP)\n",
      "- Deep learning methods require substantial amounts of manually labeled data, which limits their applicability in many domains\n",
      "- Models that can leverage linguistic information from unlabeled data provide a valuable alternative to gathering more annotation\n",
      "- Learning good representations in an unsupervised fashion can provide a significant performance boost\n",
      "- Pre-trained word embeddings have been extensively used to improve performance on a range of NLP tasks\n",
      "- Leveraging more than word-level information from unlabeled text is challenging due to uncertainties in optimization objectives and transfer techniques\n",
      "- The paper proposes a semi-supervised approach for language understanding tasks using a combination of unsupervised pre-training and supervised fine-tuning\n",
      "- The approach uses a two-stage training procedure and the Transformer model architecture\n",
      "- The approach outperforms discriminatively trained models that employ architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied\n",
      "- The pre-trained model acquires useful linguistic knowledge for downstream tasks.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarys_en = dict()\n",
    "summarys_jp = dict()\n",
    "for section_name in sections.keys():\n",
    "    gpt_prompt = f'''\n",
    "    Summarize the text below as a bullet point list of the most important points.\n",
    "\n",
    "    Text: \"\"\"\n",
    "    {sections[section_name]}\n",
    "    \"\"\"\n",
    "    '''\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": gpt_prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    summarys_en[section_name] = response['choices'][0]['message']['content']\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please translate texts into Japanese. 英語を日本語に翻訳して下さい\"},\n",
    "            {\"role\": \"user\", \"content\": summarys_en[section_name]},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    summarys_jp[section_name] = response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for section_name in summarys_en.keys():\n",
    "#     print(section_name)\n",
    "#     print(summarys_en[section_name])\n",
    "#     print(summarys_jp[section_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatPDFのような仕組みを作ろう\n",
    "- [ChatPDF](https://www.chatpdf.com/)\n",
    "    - https://pbs.twimg.com/media/FsPqJy6aUAINwq0?format=jpg&name=large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: pdf_files/language_understanding_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "pdf_url = 'https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf'\n",
    "r = requests.get(pdf_url)\n",
    "if r.status_code != 200:\n",
    "    raise ValueError(\n",
    "        \"Check the url of your file; returned status code %s\"\n",
    "        % r.status_code\n",
    "    )\n",
    "\n",
    "# ファイル名を取得します\n",
    "parsed_url = urlparse(pdf_url)\n",
    "file_name = os.path.basename(parsed_url.path)\n",
    "\n",
    "# pdf_filesディレクトリを作成し、ファイルを保存します\n",
    "pdf_files_directory = Path(\"pdf_files\")\n",
    "pdf_files_directory.mkdir(exist_ok=True)\n",
    "file_path = pdf_files_directory / file_name\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "print(f\"File saved at: {file_path}\")\n",
    "from pdfminer.high_level import extract_text\n",
    "text = extract_text(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n', ' ')\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10631\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U tiktoken\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "num_tokens = len(encoding.encode(text))\n",
    "# https://platform.openai.com/docs/models/gpt-3-5\n",
    "# モデルに入れられるtoken数は4096\n",
    "# GPT-4は32k, 64kまで扱える\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'openai[embeddings]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "from typing import List\n",
    "\n",
    "# 仮定したモジュールを使用しています。実際には適切なモジュールをインポートして使用してください。\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "@dataclass\n",
    "class Page:\n",
    "    page_number: int\n",
    "    text: str\n",
    "    embedding: List[float]\n",
    "\n",
    "def extract_page_text(pdf_file):\n",
    "    pages_text = []\n",
    "    for page_layout in extract_pages(pdf_file):\n",
    "        single_page_text = ''\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                single_page_text += element.get_text().replace('\\n', ' ')\n",
    "        pages_text.append(single_page_text)\n",
    "    return pages_text\n",
    "file_path = 'pdf_files/language_understanding_paper.pdf'\n",
    "pages_text = extract_page_text(file_path)\n",
    "# for page_text in pages_text:\n",
    "#     print(len(encoding.encode(page_text)))\n",
    "\n",
    "pages = []\n",
    "for idx, page_text in enumerate(pages_text):\n",
    "    # https://github.com/openai/openai-cookbook/blob/main/examples/Semantic_text_search_using_embeddings.ipynb\n",
    "    embedding = get_embedding(\n",
    "        page_text,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    page = Page(page_number=idx + 1, text=page_text, embedding=embedding)\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Improving Language Understanding by Generative...</td>\n",
       "      <td>[-0.010624888353049755, -0.0002075700904242694...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>In this paper, we explore a semi-supervised ap...</td>\n",
       "      <td>[-0.001758279511705041, -0.002217849250882864,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pre-trained language or machine translation mo...</td>\n",
       "      <td>[-0.005748812574893236, 0.0015207912074401975,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Figure 1: (left) Transformer architecture and ...</td>\n",
       "      <td>[-0.0037100473418831825, -0.011732332408428192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Table 1: A list of the different tasks and dat...</td>\n",
       "      <td>[-0.00776058342307806, 0.006178564857691526, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Table 2: Experimental results on natural langu...</td>\n",
       "      <td>[-0.01649334840476513, 0.01438925787806511, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Table 4: Semantic similarity and classiﬁcation...</td>\n",
       "      <td>[-0.005145553965121508, -0.007219440769404173,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Table 5: Analysis of various model ablations o...</td>\n",
       "      <td>[-0.018282189965248108, 0.0034548065159469843,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[2] J. L. Ba, J. R. Kiros, and G. E. Hinton. L...</td>\n",
       "      <td>[-0.02173006534576416, 0.007508637383580208, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[24] F. Jiao, S. Wang, C.-H. Lee, R. Greiner, ...</td>\n",
       "      <td>[-0.004755450412631035, -0.0022865389473736286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[46] A. Rahman and V. Ng. Resolving complex ca...</td>\n",
       "      <td>[-0.020036006346344948, -0.0020227322820574045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[68] D. Yu, L. Deng, and G. Dahl. Roles of pre...</td>\n",
       "      <td>[-0.022569747641682625, -0.003746930742636323,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number                                               text  \\\n",
       "0             1  Improving Language Understanding by Generative...   \n",
       "1             2  In this paper, we explore a semi-supervised ap...   \n",
       "2             3  pre-trained language or machine translation mo...   \n",
       "3             4  Figure 1: (left) Transformer architecture and ...   \n",
       "4             5  Table 1: A list of the different tasks and dat...   \n",
       "5             6  Table 2: Experimental results on natural langu...   \n",
       "6             7  Table 4: Semantic similarity and classiﬁcation...   \n",
       "7             8  Table 5: Analysis of various model ablations o...   \n",
       "8             9  [2] J. L. Ba, J. R. Kiros, and G. E. Hinton. L...   \n",
       "9            10  [24] F. Jiao, S. Wang, C.-H. Lee, R. Greiner, ...   \n",
       "10           11  [46] A. Rahman and V. Ng. Resolving complex ca...   \n",
       "11           12  [68] D. Yu, L. Deng, and G. Dahl. Roles of pre...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.010624888353049755, -0.0002075700904242694...  \n",
       "1   [-0.001758279511705041, -0.002217849250882864,...  \n",
       "2   [-0.005748812574893236, 0.0015207912074401975,...  \n",
       "3   [-0.0037100473418831825, -0.011732332408428192...  \n",
       "4   [-0.00776058342307806, 0.006178564857691526, 0...  \n",
       "5   [-0.01649334840476513, 0.01438925787806511, 0....  \n",
       "6   [-0.005145553965121508, -0.007219440769404173,...  \n",
       "7   [-0.018282189965248108, 0.0034548065159469843,...  \n",
       "8   [-0.02173006534576416, 0.007508637383580208, 0...  \n",
       "9   [-0.004755450412631035, -0.0022865389473736286...  \n",
       "10  [-0.020036006346344948, -0.0020227322820574045...  \n",
       "11  [-0.022569747641682625, -0.003746930742636323,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pagesリストをDataFrameに変換\n",
    "pages_df = pd.DataFrame(pages)\n",
    "pages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 pages similar to the query 'この論文の手法の重要な点は何ですか？':\n",
      "\n",
      "Page 7 (similarity: 0.7406577225533086):\n",
      "\n",
      "Page 1 (similarity: 0.7346770669052388):\n",
      "\n",
      "Page 6 (similarity: 0.7345843612395349):\n"
     ]
    }
   ],
   "source": [
    "# query文字列とそのembedding\n",
    "query = \"この論文の手法の重要な点は何ですか？\"\n",
    "query_embedding = get_embedding(\n",
    "        query,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "\n",
    "# コサイン類似度を計算\n",
    "pages_df['similarity'] = pages_df['embedding'].apply(lambda x: cosine_similarity(x, query_embedding))\n",
    "\n",
    "# 類似度の降順に並び替え\n",
    "sorted_pages_df = pages_df.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "# 上位n件のテキストを取得\n",
    "n = 3\n",
    "top_n_pages = sorted_pages_df.head(n)\n",
    "\n",
    "# 結果を表示\n",
    "print(f\"Top {n} pages similar to the query '{query}':\")\n",
    "context_texts = []\n",
    "for index, row in top_n_pages.iterrows():\n",
    "    print(f\"\\nPage {row.page_number} (similarity: {row.similarity}):\")\n",
    "    # print(row.text)\n",
    "    context_texts.append(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\n",
      "\n",
      "Context:\n",
      "\n",
      "* Table 4: Semantic similarity and classiﬁcation results, comparing our model with current state-of-the- art methods. All task evaluations in this table were done using the GLUE benchmark. (mc= Mathews correlation, acc=Accuracy, pc=Pearson correlation) Method Classiﬁcation Semantic Similarity GLUE CoLA SST2 MRPC STSB QQP (F1) (F1) (mc) (acc) (pc) Sparse byte mLSTM [16] TF-KLD [23] ECNU (mixed ensemble) [60] Single-task BiLSTM + ELMo + Attn [64] Multi-task BiLSTM + ELMo + Attn [64] Finetuned Transformer LM (ours) - - - 35.0 18.9 45.4 93.2 - - 90.2 91.6 91.3 - 86.0 - 80.2 83.5 82.3 - - 81.0 55.5 72.8 82.0 - - - - - - 66.1 63.3 70.3 64.8 68.9 72.8 Overall, our approach achieves new state-of-the-art results in 9 out of the 12 datasets we evaluate on, outperforming ensembles in many cases. Our results also indicate that our approach works well across datasets of different sizes, from smaller datasets such as STS-B (≈5.7k training examples) – to the largest one – SNLI (≈550k training examples). 5 Analysis Impact of number of layers transferred We observed the impact of transferring a variable number of layers from unsupervised pre-training to the supervised target task. Figure 2(left) illustrates the performance of our approach on MultiNLI and RACE as a function of the number of layers transferred. We observe the standard result that transferring embeddings improves performance and that each transformer layer provides further beneﬁts up to 9% for full transfer on MultiNLI. This indicates that each layer in the pre-trained model contains useful functionality for solving target tasks. Figure 2: (left) Effect of transferring increasing number of layers from the pre-trained language model on RACE and MultiNLI. (right) Plot showing the evolution of zero-shot performance on different tasks as a function of LM pre-training updates. Performance per task is normalized between a random guess baseline and the current state-of-the-art with a single model. Zero-shot Behaviors We’d like to better understand why language model pre-training of transform- ers is effective. A hypothesis is that the underlying generative model learns to perform many of the tasks we evaluate on in order to improve its language modeling capability and that the more structured 7 \n",
      "* Improving Language Understanding by Generative Pre-Training Alec Radford OpenAI alec@openai.com Karthik Narasimhan OpenAI karthikn@openai.com Tim Salimans OpenAI tim@openai.com Ilya Sutskever OpenAI ilyasu@openai.com Abstract Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI). 1 Introduction The ability to learn effectively from raw text is crucial to alleviating the dependence on supervised learning in natural language processing (NLP). Most deep learning methods require substantial amounts of manually labeled data, which restricts their applicability in many domains that suffer from a dearth of annotated resources [61]. In these situations, models that can leverage linguistic information from unlabeled data provide a valuable alternative to gathering more annotation, which can be time-consuming and expensive. Further, even in cases where considerable supervision is available, learning good representations in an unsupervised fashion can provide a signiﬁcant performance boost. The most compelling evidence for this so far has been the extensive use of pre- trained word embeddings [10, 39, 42] to improve performance on a range of NLP tasks [8, 11, 26, 45]. Leveraging more than word-level information from unlabeled text, however, is challenging for two main reasons. First, it is unclear what type of optimization objectives are most effective at learning text representations that are useful for transfer. Recent research has looked at various objectives such as language modeling [44], machine translation [38], and discourse coherence [22], with each method outperforming the others on different tasks.1 Second, there is no consensus on the most effective way to transfer these learned representations to the target task. Existing techniques involve a combination of making task-speciﬁc changes to the model architecture [43, 44], using intricate learning schemes [21] and adding auxiliary learning objectives [50]. These uncertainties have made it difﬁcult to develop effective semi-supervised learning approaches for language processing. 1https://gluebenchmark.com/leaderboard Preprint. Work in progress. \n",
      "* Table 2: Experimental results on natural language inference tasks, comparing our model with current state-of-the-art methods. 5x indicates an ensemble of 5 models. All datasets use accuracy as the evaluation metric. Method MNLI-m MNLI-mm SNLI SciTail QNLI RTE ESIM + ELMo [44] (5x) CAFE [58] (5x) Stochastic Answer Network [35] (3x) CAFE [58] GenSen [64] Multi-task BiLSTM + Attn [64] Finetuned Transformer LM (ours) - 80.2 80.6 78.7 71.4 72.2 82.1 - 79.0 80.1 77.9 71.3 72.1 81.4 89.3 89.3 - 88.5 - - - - - 83.3 - - 89.9 88.3 - - - - - - 82.3 82.1 88.1 59.2 61.7 56.0 Table 3: Results on question answering and commonsense reasoning, comparing our model with current state-of-the-art methods.. 9x means an ensemble of 9 models. Method Story Cloze RACE-m RACE-h RACE val-LS-skip [55] Hidden Coherence Model [7] Dynamic Fusion Net [67] (9x) BiAttention MRU [59] (9x) 76.5 77.6 - - Finetuned Transformer LM (ours) 86.5 - - 55.6 60.2 62.9 - - 49.4 50.3 57.4 - - 51.2 53.3 59.0 Question answering and commonsense reasoning Another task that requires aspects of single and multi-sentence reasoning is question answering. We use the recently released RACE dataset [30], consisting of English passages with associated questions from middle and high school exams. This corpus has been shown to contain more reasoning type questions that other datasets like CNN [19] or SQuaD [47], providing the perfect evaluation for our model which is trained to handle long-range contexts. In addition, we evaluate on the Story Cloze Test [40], which involves selecting the correct ending to multi-sentence stories from two options. On these tasks, our model again outperforms the previous best results by signiﬁcant margins - up to 8.9% on Story Cloze, and 5.7% overall on RACE. This demonstrates the ability of our model to handle long-range contexts effectively. Semantic Similarity Semantic similarity (or paraphrase detection) tasks involve predicting whether two sentences are semantically equivalent or not. The challenges lie in recognizing rephrasing of concepts, understanding negation, and handling syntactic ambiguity. We use three datasets for this task – the Microsoft Paraphrase corpus (MRPC) [14] (collected from news sources), the Quora Question Pairs (QQP) dataset [9], and the Semantic Textual Similarity benchmark (STS-B) [6]. We obtain state-of-the-art results on two of the three semantic similarity tasks (Table 4) with a 1 point absolute gain on STS-B. The performance delta on QQP is signiﬁcant, with a 4.2% absolute improvement over Single-task BiLSTM + ELMo + Attn. Classiﬁcation Finally, we also evaluate on two different text classiﬁcation tasks. The Corpus of Linguistic Acceptability (CoLA) [65] contains expert judgements on whether a sentence is grammatical or not, and tests the innate linguistic bias of trained models. The Stanford Sentiment Treebank (SST-2) [54], on the other hand, is a standard binary classiﬁcation task. Our model obtains an score of 45.4 on CoLA, which is an especially big jump over the previous best result of 35.0, showcasing the innate linguistic bias learned by our model. The model also achieves 91.3% accuracy on SST-2, which is competitive with the state-of-the-art results. We also achieve an overall score of 72.8 on the GLUE benchmark, which is signiﬁcantly better than the previous best of 68.9. 6 \n",
      "\n",
      " Q: この論文の手法の重要な点は何ですか？\n",
      " A:\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\n",
    "SEPARATOR = \"\\n* \"\n",
    "header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "gpt_prompt = \"\"\n",
    "gpt_prompt += header\n",
    "for context_text in context_texts:\n",
    "    gpt_prompt += SEPARATOR\n",
    "    gpt_prompt += context_text\n",
    "gpt_prompt += \"\\n\\n Q: \" + query + \"\\n A:\"\n",
    "print(gpt_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please answer in Japanese. 回答は日本語でお願いします。\"},\n",
    "        {\"role\": \"user\", \"content\": gpt_prompt},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この論文の手法の重要な点は、大規模な未ラベルのテキストコーパスを用いた言語モデルの生成的事前学習によって、多様な自然言語理解タスクにおいて高い性能を発揮することができることです。また、タスクに応じた入力変換を行うことで、モデルアーキテクチャを最小限変更することで効果的な転移学習を実現しています。\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
